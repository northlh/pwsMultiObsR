---
title: "example01_default"
author: "Lauren North"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{example01_default}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# 1 Setup Directories

## 1.1 Setup root directory
The root directory is where you would like your work to be placed, and the project name is a subdirectory for a specific method, catchment, or whatever the user decides. 

```{r}

rm(list = ls()) # Clears Global Environment!!!
library(pwsMultiObsR)

dir_root <- file.path("/Users/lnorth/Desktop/test_pwsMultiObsR")
project_name <- "example_east"

```

## 1.2 Create Project
This function creates a new folder in "dir_root" called "projects". From here on out, the package will operate within the projects folder. You can have multiple projects (specified by project_name above).

```{r}

?pwsMultiObsR::fm_project_create

dir_project <- fm_project_create(dir_root = dir_root,
                                 project_name = project_name)

```

## 1.3 Create Trial
*STOP:*
You must add files to the "default_input" directory that was just created in the project folder. This includes:
      • myparam.param
      • control.control
      • prcp.cbh
      • tmax.cbh
      • tmin.cbh

*For this example:*
In the package root all necessary files for a run are contained in "inst/example_inputs/". All contents will be automatically copied to the new project by the function below, but this will need to be done manually in all other projects.

NOTE:
The climate-by-HRU (.cbh) files are the same as the .day files from the National Hydrologic Model (NHM). They files need to match the names above to be compatible with pws. These are tab delimited meteorologic inputs, see USGS documentaiton for more information https://pubs.usgs.gov/tm/6b7/pdf/tm6-b7.pdf.

```{r}

?pwsMultiObsR::load_example_inputs

load_example_inputs(
  dir_root = dir_root,
  project_name = project_name,
  example_catchment = "TaylorRiv"
)

```

The function below creates a "trial" which is a sub directory within the project. The intent of the trials is to have the default, sensitivity. and uncertainty simulations belong to the same project, and call the same GIS files, default inputs, etc..

NOTE:
There should only be one default run per project. The folder for project_name/output/trial_001 will be empty because the default results are stored in the default_output directory. Future developments include forcing the first trial to be default, overwrite protection, and increasing flexibility for one-off simulations. 

```{r}

?pwsMultiObsR::fm_trial_create

directories <- fm_trial_create(
  dir_root = dir_root,
  project_name = project_name,
  type = "default"
)

# # If you have already created the trial and want to come back to it, use this:
# 
# directories <- fm_trial_set(
#   dir_root = dir_root,
#   project_name = project_name,
#   trial_number = 1
# )

```

## 2 Load Observations

# 2,1 View SNOTEL and USGS Stations
See where the USGS steamgages and SNOTEL observation stations are realtive the the "model_nhru.shp" file copied over in the steps above. 

```{r}

plot_snotel(dir_root = dir_root, project_name = project_name)

plot_usgs(dir_root = dir_root, project_name = project_name)

```

# 2.2 Align Stations with the Model
You'll notice that some of the SNOTEL stations lie close to an HRU border, an overall basin boundary, or that the NHM segments are unclear. You may need to do some additional investigation for these stations to determine which model HRU or segment they belong to. Once you have determined your observation network, write the stations into a list as shown in the following chunk. This has already been completed for this example.

See the NRCS iMap to view SNOTEL gauges and their site IDs: https://www.nrcs.usda.gov/programs-initiatives/sswsf-snow-survey-and-water-supply-forecasting-program/national-water-and

```{r}

# # EAST RIVER
# nrcs_stations <- list(CO = list(site_ids = c(380, 737),
#                                   hru_ids = c(8,10)))
# 
# usgs_stations <- list(site_ids = c("09112500", "09112200"),
#                       seg_ids = c(5,4))


# # BLUE RIVER
# nrcs_stations <- list(CO = list(site_ids = c(531),
#                                   hru_ids = c(2)))
# 
# usgs_stations <- list(site_ids = c("09046490", "09046600"),
#                       seg_ids = c(3,1))



# # DOLORES
# nrcs_stations <- list(CO = list(site_ids = c(465, 586, 739, 1060, 1185),
#                                   hru_ids = c(9, 9, 7, 2, 11)))
# 
# usgs_stations <- list(site_ids = c("09165000", "09166500"),
#                       seg_ids = c(7, 4))



# TAYLOR RIVER
nrcs_stations <- list(CO = list(site_ids = c(1141),
                                  hru_ids = c(2)))

usgs_stations <- list(site_ids = c("09107000"),
                      seg_ids = c(2))
```

## 2.3  Read in SNOTEL data
This function uses a url connection, and times out at 60 seconds which may require more than one attempt if internet is slow. Currently it is hard-coded to only extract SWE and soil moisture, but it can do all others. It will extract for the full length of available record. This will create the observation data in "/projects/project_name/obs/nrcs/".

```{r}

nrcs_data <- retrieve_nrcs(
  dir_root = dir_root,
  project_name = project_name,
  nrcs_stations = nrcs_stations,
  overwrite = FALSE)

```

## 2.4 Read in USGS data
This function is relatively fast, using the DataRetrieval package. It requires a date range for the readNWIS function (okay to overshoot period of record). This will create the observation data in "/projects/project_name/obs/usgs/".

```{r}

usgs_data <- retrieve_q(
  dir_root = dir_root,
  project_name = project_name,
  usgs_stations = usgs_stations,
  start_date = "1970-10-01",
  end_date = "2023-09-30",
  overwrite = FALSE)

```

# 3 Run Model
If you run into errors here, be sure to reset the working directory and/or restarting the R session before trying again. Troubleshooting steps may involve checking the filenames in the default_input directory, checking some of the variables or file calls in the control file, or checking your python or pywatershed environment name. A default run may take several minutes depending on you machine and modeling domain. In this example, we run (43 yrs) of the 10 HRU East River watershed using default inputs from the NHM.

```{r}

?run_default

run_default(dir_root = dir_root,
            project_name = project_name,
            trial_number = directories$trial_number)


```

# 4 Analyze Output
The function calc_gof post-processes the model results using pre-selected "goodness of fit" functions. It writes goodness of fit results in lists named "list_gof_obsType" in the default ouput directory.

```{r}

?calc_gof

gof_results <- calc_gof(
  dir_root = dir_root,
  project_name = project_name,
  trial_number = directories$trial_number,
  start_year = 1982,
  end_year = 2022,
  hru_out_names = "pkwater_equiv",
  seg_out_names = "seg_outflow",
  default = TRUE
)

```



